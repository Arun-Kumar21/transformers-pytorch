# Transformers

Trying to implement various transformers; currently working on the En-De Transformer from the original "Attention Is All You Need" paper. I also take reference from Hridaya's En-Es Transformer model.

## References

- [Attention Is All You Need (Original Paper)](https://arxiv.org/abs/1706.03762)
- [Annotated Transformer (Harvard NLP)](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [En-Es Transformer (ML-Scratch-Implementations by Hridaya)](https://github.com/hridaya14/ML-Scratch-Implementations/tree/main/En-Es-Transformer)