{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB1L3ufhNe13"
      },
      "source": [
        "# En - De Transformer using Pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "J3IUHv7VNmHj",
        "outputId": "81c8a3c4-33dd-41c2-c421-74c75ef01485"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "15J_3YFBOJ2s"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "from datasets import load_dataset\n",
        "import sentencepiece as spm\n",
        "import os\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiErWVNHWl3r",
        "outputId": "9dc7c677-9801-41f3-92ed-434c6c5d9911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTec95geVRxX"
      },
      "source": [
        "<h4>Preparing Dataset</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ysm3tb5OTVwc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DtQ84ykQVJJS",
        "outputId": "1eb0484b-db96-4898-e247-58e3ea0d7c0e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a477e92b-cff4-42bf-bec0-4092eb748165\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ENGLISH</th>\n",
              "      <th>GERMAN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>hi</td>\n",
              "      <td>hallo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hi</td>\n",
              "      <td>gru gott</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>run</td>\n",
              "      <td>lauf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>wow</td>\n",
              "      <td>potzdonner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>wow</td>\n",
              "      <td>donnerwetter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a477e92b-cff4-42bf-bec0-4092eb748165')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a477e92b-cff4-42bf-bec0-4092eb748165 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a477e92b-cff4-42bf-bec0-4092eb748165');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-49f5377d-d4b1-4cf8-997a-19543c7abb04\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49f5377d-d4b1-4cf8-997a-19543c7abb04')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-49f5377d-d4b1-4cf8-997a-19543c7abb04 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0 ENGLISH        GERMAN\n",
              "0           0      hi         hallo\n",
              "1           1      hi      gru gott\n",
              "2           2     run          lauf\n",
              "3           3     wow    potzdonner\n",
              "4           4     wow  donnerwetter"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_path = '/content/drive/My Drive/data/de_en.csv'\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUARqvj4VNu8",
        "outputId": "af2cd3a1-0cca-4dad-a98e-ccd59ee542fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pairs: 20000\n"
          ]
        }
      ],
      "source": [
        "en_sentences = df['ENGLISH'].astype(str).tolist()\n",
        "de_sentences = df['GERMAN'].astype(str).tolist()\n",
        "\n",
        "en_sentences = en_sentences[:20000]\n",
        "de_sentences = de_sentences[:20000]\n",
        "\n",
        "\n",
        "print(f\"Total pairs: {len(en_sentences)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAEVLtufVmTi",
        "outputId": "34b91605-4e31-46b1-ef11-9704fe49afc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hallo',\n",
              " 'gru gott',\n",
              " 'lauf',\n",
              " 'potzdonner',\n",
              " 'donnerwetter',\n",
              " 'feuer',\n",
              " 'hilfe',\n",
              " 'zu hulf',\n",
              " 'stopp',\n",
              " 'warte']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "de_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njUQbUtgV3qt",
        "outputId": "e8bc6560-2532-46e8-dc36-5a571a5c72b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 18000\n",
            "Validation size: 2000\n"
          ]
        }
      ],
      "source": [
        "group = list(zip(en_sentences, de_sentences))\n",
        "random.shuffle(group)\n",
        "\n",
        "# 90% train, 10% validation\n",
        "train_group = group[:int(len(group) * 0.9)]\n",
        "val_group = group[int(len(group) * 0.9):]\n",
        "\n",
        "print(f\"Train size: {len(train_group)}\")\n",
        "print(f\"Validation size: {len(val_group)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORE3W4QcWREj",
        "outputId": "94b2cf59-11e7-4803-f145-e4a1abdba8fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved train/valid splits in Drive!\n"
          ]
        }
      ],
      "source": [
        "output_dir = '/content/drive/My Drive/data/'\n",
        "\n",
        "with open(output_dir + 'train.en', 'w', encoding='utf-8') as f_en, \\\n",
        "     open(output_dir + 'train.de', 'w', encoding='utf-8') as f_de:\n",
        "    for en, de in train_group:\n",
        "        f_en.write(en.strip() + \"\\n\")\n",
        "        f_de.write(de.strip() + \"\\n\")\n",
        "\n",
        "with open(output_dir + 'valid.en', 'w', encoding='utf-8') as f_en, \\\n",
        "     open(output_dir + 'valid.de', 'w', encoding='utf-8') as f_de:\n",
        "    for en, de in val_group:\n",
        "        f_en.write(en.strip() + \"\\n\")\n",
        "        f_de.write(de.strip() + \"\\n\")\n",
        "\n",
        "print(\"Saved train/valid splits in Drive!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imALluE0aNTE"
      },
      "source": [
        "<h4>Tokenizer</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "6HNssNyRXfaT"
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "4PN0OfkPaXsH"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/drive/My Drive/data/\"\n",
        "spm_dir = \"/content/drive/My Drive/data/spm/\"\n",
        "\n",
        "os.makedirs(spm_dir, exist_ok=True)\n",
        "\n",
        "train_en = os.path.join(data_dir, \"train.en\")\n",
        "train_de = os.path.join(data_dir, \"train.de\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "7J_MwzzTauMQ"
      },
      "outputs": [],
      "source": [
        "spm.SentencePieceTrainer.Train(\n",
        "    input=train_en,\n",
        "    model_prefix=f\"{spm_dir}en\",\n",
        "    vocab_size=8000,\n",
        "    character_coverage=1.0,\n",
        "    model_type=\"bpe\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "82c7342e"
      },
      "outputs": [],
      "source": [
        "spm.SentencePieceTrainer.Train(\n",
        "    input=train_de,\n",
        "    model_prefix=f\"{spm_dir}de\",\n",
        "    vocab_size=8000,\n",
        "    character_coverage=1.0,\n",
        "    model_type=\"bpe\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rM8OrqLe30v",
        "outputId": "e49917f2-9f30-4be7-8714-2eca6a043d9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sp_en = spm.SentencePieceProcessor()\n",
        "sp_en.load(f\"{spm_dir}en.model\")\n",
        "\n",
        "sp_de = spm.SentencePieceProcessor()\n",
        "sp_de.load(f\"{spm_dir}de.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dKA9SOZfUAe",
        "outputId": "309d9915-1b3e-41fb-e482-cc5d0dcb5814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "en encoding: [3, 141, 70, 1432]\n",
            "de encoding: [15, 303, 464, 1764]\n",
            "en decoding: i love this song\n",
            "de decoding: ich liebe dieses lied\n"
          ]
        }
      ],
      "source": [
        "sample_en = \"i love this song\"\n",
        "sample_de = \"ich liebe dieses lied\"\n",
        "\n",
        "encode_en = sp_en.encode(sample_en, out_type=int)\n",
        "encode_de = sp_de.encode(sample_de, out_type=int)\n",
        "\n",
        "print(\"en encoding:\", encode_en)\n",
        "print(\"de encoding:\", encode_de)\n",
        "\n",
        "print(\"en decoding:\", sp_en.decode(encode_en))\n",
        "print(\"de decoding:\", sp_de.decode(encode_de))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkaWty3oQvls"
      },
      "source": [
        "<h4>Creating Dataset</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "a6b7f7c1"
      },
      "outputs": [],
      "source": [
        "class DeEnPairDataset(Dataset):\n",
        "    def __init__(self, en_file, de_file, sp_en, sp_de):\n",
        "        \"Read file from drive\"\n",
        "        with open(en_file, 'r') as f:\n",
        "            self.en_sentences = [line.strip() for line in f.readlines()]\n",
        "        with open(de_file, 'r') as f:\n",
        "            self.de_sentences = [line.strip() for line in f.readlines()]\n",
        "        self.sp_en = sp_en\n",
        "        self.sp_de = sp_de\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.en_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"return (De tensor, En tensor)\"\n",
        "        en_encoded = self.sp_en.encode(self.en_sentences[idx], out_type=int)\n",
        "        de_encoded = self.sp_de.encode(self.de_sentences[idx], out_type=int)\n",
        "        return torch.tensor(en_encoded, dtype=torch.long), torch.tensor(de_encoded, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0iOHC2-w2pr",
        "outputId": "80c1c5fb-b3e7-4062-e217-0849626c86e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18000 2000\n",
            "(tensor([493, 138,  44]), tensor([721, 220,  84]))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('cook for me', 'koch fur mich')"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds = DeEnPairDataset(os.path.join(data_dir, \"train.en\"), os.path.join(data_dir, \"train.de\"), sp_en, sp_de)\n",
        "val_ds = DeEnPairDataset(os.path.join(data_dir, \"valid.en\"), os.path.join(data_dir, \"valid.de\"), sp_en, sp_de)\n",
        "\n",
        "print(len(train_ds), len(val_ds))\n",
        "\n",
        "print(train_ds[0])\n",
        "\n",
        "sp_en.decode(train_ds[0][0].tolist()), sp_de.decode(train_ds[0][1].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSHgTZBcRHtH"
      },
      "source": [
        "<h4>Fixed size tensors (input, target) in batch</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "d9f6e0f6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "max_seq_len = 100\n",
        "pad_idx = 0\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"Return fixed size tensor\"\n",
        "    srcs, tgts = zip(*batch)\n",
        "    batch_size = len(batch)\n",
        "\n",
        "    src_batch = []\n",
        "    tgt_batch = []\n",
        "\n",
        "    for src in srcs:\n",
        "        if len(src) < max_seq_len:\n",
        "            \"Padding\"\n",
        "            padded = torch.cat([src, torch.tensor([pad_idx] * (max_seq_len - len(src)), dtype=torch.long)])\n",
        "        else:\n",
        "            \"Truncate\"\n",
        "            padded = src[:max_seq_len]\n",
        "        src_batch.append(padded)\n",
        "\n",
        "    for tgt in tgts:\n",
        "        if len(tgt) < max_seq_len:\n",
        "            padded = torch.cat([tgt, torch.tensor([pad_idx] * (max_seq_len - len(tgt)), dtype=torch.long)])\n",
        "        else:\n",
        "            padded = tgt[:max_seq_len]\n",
        "        tgt_batch.append(padded)\n",
        "\n",
        "    src_batch = torch.stack(src_batch)\n",
        "    tgt_batch = torch.stack(tgt_batch)\n",
        "\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlXn6BooLNeA",
        "outputId": "2baff2d2-0a4e-4c01-eb28-d507bdefa6f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "563"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# (batch_size, seq)-> (32, 625)\n",
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obFifFvwRXVB"
      },
      "source": [
        "<h4>Model</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "d7JwA3boP5Oi"
      },
      "outputs": [],
      "source": [
        "# Hyper parameters\n",
        "\n",
        "lr = 3e-4\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n_embd = 512\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.1\n",
        "vocab_size = 8000\n",
        "max_seq_len=100\n",
        "\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "cG-xDKbrRnBq"
      },
      "outputs": [],
      "source": [
        "def clones(module, N):\n",
        "  \"Create N identical layers.\"\n",
        "  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "i1bGawNTSh9y"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  \"Normalize features\"\n",
        "  def __init__(self, features, eps=1e-6):\n",
        "    super(LayerNorm, self).__init__()\n",
        "    self.a_2 = nn.Parameter(torch.ones(features))\n",
        "    self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "    self.eps = eps\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(-1, keepdim=True)\n",
        "    std = x.std(-1, keepdim=True)\n",
        "    return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "vnHc00vnXV64"
      },
      "outputs": [],
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "  \"Residual connection followed by layer norm\"\n",
        "  def __init__(self, size, dropout):\n",
        "    super(SublayerConnection, self).__init__()\n",
        "    self.layer_norm = LayerNorm(size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, sublayer):\n",
        "    return x + self.dropout(sublayer(self.layer_norm(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "WkyLuNOAZDx0"
      },
      "outputs": [],
      "source": [
        "def attention(q, k, v, mask=None, dropout=None):\n",
        "  \"Compute Scaled Dot Product Attention (Attention score)\"\n",
        "  dim_k = k.size(-1)\n",
        "  score = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(dim_k)\n",
        "  if mask is not None:\n",
        "    score = score.masked_fill(mask == 0, -1e9)\n",
        "  att_w = score.softmax(dim=-1)\n",
        "  if dropout is not None:\n",
        "    att_w = dropout(att_w)\n",
        "\n",
        "  return torch.matmul(att_w, v), att_w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "v2fXvMYecOwJ"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "  def __init__(self, n_head, n_embd, dropout=0.1):\n",
        "    super(MultiHeadedAttention, self).__init__()\n",
        "    assert n_embd % n_head == 0, \"can't divide n_embd by n_head\"\n",
        "    self.n_head = n_head\n",
        "    self.n_embd = n_embd\n",
        "    self.dim_k = n_embd // n_head\n",
        "    self.Ws = clones(nn.Linear(n_embd, n_embd), 4)\n",
        "    self.attn = None\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, q, k, v, mask=None):\n",
        "    if mask is not None:\n",
        "      mask = mask.unsqueeze(1)\n",
        "    n_batches = q.size(0)\n",
        "\n",
        "    Q = self.Ws[0](q).view(n_batches, -1, self.n_head, self.dim_k).transpose(1, 2)\n",
        "    K = self.Ws[1](k).view(n_batches, -1, self.n_head, self.dim_k).transpose(1, 2)\n",
        "    V = self.Ws[2](v).view(n_batches, -1, self.n_head, self.dim_k).transpose(1, 2)\n",
        "\n",
        "    x, self.attn = attention(Q, K, V, mask=mask, dropout=self.dropout)\n",
        "\n",
        "    \"Concatenating all heads\"\n",
        "    x = x.transpose(1, 2).contiguous().view(n_batches, -1, self.n_head * self.dim_k)\n",
        "\n",
        "    return self.Ws[-1](x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "D_kjvNJKjEqv"
      },
      "outputs": [],
      "source": [
        "class FeedForwardLayer(nn.Module):\n",
        "  def __init__(self, n_embd, dropout):\n",
        "    super(FeedForwardLayer, self).__init__()\n",
        "    self.ff = nn.Sequential(\n",
        "        nn.Linear(n_embd, 4 * n_embd),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * n_embd, n_embd),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.ff(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "PNQGbYa_l3YE"
      },
      "outputs": [],
      "source": [
        "class Embeddings(nn.Module):\n",
        "  def __init__(self, vocab_size, n_embd):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, n_embd)\n",
        "    self.scale = n_embd ** 0.5\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.embedding(x) * self.scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "tgqx7mjXp502"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, n_embd, max_len=100):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "\n",
        "    pe = torch.zeros(max_len, n_embd)\n",
        "    pos = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, n_embd, 2) * -(math.log(10000.0) / n_embd)) # e ^ [-ln(10000) * (2i/ n_embd)]\n",
        "    pe[:, 0::2] = torch.sin(pos * div_term)\n",
        "    pe[:, 1::2] = torch.cos(pos * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.pe[:, :x.size(1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "9GGXZndQrqMv"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  \"Consist of multi-head attention and feed forward\"\n",
        "  def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.self_attn = self_attn\n",
        "    self.feed_forward = feed_forward\n",
        "    self.add_and_norm = clones(SublayerConnection(size, dropout), 2)\n",
        "    self.size = size\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x = self.add_and_norm[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "    x = self.add_and_norm[1](x, self.feed_forward)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "mk5TuGSeuw8v"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  \"Consist of multi-head attn, src_attn, feed forward\"\n",
        "  def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "    self.size = size\n",
        "    self.self_attn = self_attn\n",
        "    self.src_attn = src_attn\n",
        "    self.feed_forward = feed_forward\n",
        "    self.add_and_norm = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "  def forward(self, x, encoder_op, src_mask, tgt_mask):\n",
        "    x = self.add_and_norm[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "    x = self.add_and_norm[1](x, lambda x: self.src_attn(x, encoder_op, encoder_op, src_mask))\n",
        "    x = self.add_and_norm[2](x, self.feed_forward)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "y75jPbRrwruN"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, layer, N):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.layers = clones(layer, N)\n",
        "    self.norm = LayerNorm(layer.size)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, mask)\n",
        "    return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "q42p1VEdyack"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, layer, N):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.layers = clones(layer, N)\n",
        "    self.norm = LayerNorm(layer.size)\n",
        "\n",
        "  def forward(self, x, encoder_op, src_mask, tgt_mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, encoder_op, src_mask, tgt_mask)\n",
        "    return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiWXDvNryyWT"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self, src_vocab_size, tgt_vocab_size, n_embd, n_head, n_layer, dropout, max_seq_len):\n",
        "    super(Transformer, self).__init__()\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(n_head, n_embd, dropout)\n",
        "    ff = FeedForwardLayer(n_embd, dropout)\n",
        "    position = PositionalEncoding(n_embd, max_seq_len)\n",
        "\n",
        "    self.encoder = Encoder(EncoderLayer(n_embd, c(attn), c(ff), dropout), n_layer)\n",
        "    self.decoder = Decoder(DecoderLayer(n_embd, c(attn), c(attn), c(ff), dropout), n_layer)\n",
        "    self.src_embed = nn.Sequential(Embeddings(src_vocab_size, n_embd), c(position))\n",
        "    self.tgt_embed = nn.Sequential(Embeddings(tgt_vocab_size, n_embd), c(position))\n",
        "    self.generator = nn.Linear(n_embd, tgt_vocab_size)\n",
        "\n",
        "  def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "    \"Process src and tgt sequences.\"\n",
        "    encoded_src = self.encode(src, src_mask)\n",
        "    decoded_tgt = self.decode(encoded_src, src_mask, tgt, tgt_mask)\n",
        "\n",
        "    return self.generator(decoded_tgt)\n",
        "\n",
        "  def encode(self, src, src_mask):\n",
        "    return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "  def decode(self, encoder_op, src_mask, tgt, tgt_mask):\n",
        "    tgt_mask = make_tgt_mask(tgt, pad_idx).to(tgt.device)\n",
        "    return self.decoder(self.tgt_embed(tgt), encoder_op, src_mask, tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "J0Pogb5E6qcl"
      },
      "outputs": [],
      "source": [
        "def make_src_mask(src, pad_idx):\n",
        "    \"Create a mask to hide padding tokens in the source sequence.\"\n",
        "    return (src != pad_idx).unsqueeze(1)\n",
        "\n",
        "def make_tgt_mask(tgt, pad_idx):\n",
        "    \"Create a mask to hide padding tokens in the target sequence and future tokens.\"\n",
        "    # (B, seq_len, seq_len)\n",
        "    tgt_pad_mask = (tgt != pad_idx).unsqueeze(-2)\n",
        "    tgt_seq_len = tgt.size(-1)\n",
        "    subsequent_mask = torch.tril(torch.ones(tgt_seq_len, tgt_seq_len, dtype=torch.bool, device=tgt.device))\n",
        "    # (B, seq_len, seq_len) & (1, seq_len, seq_len) -> (B, seq_len, seq_len)\n",
        "    return tgt_pad_mask & subsequent_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Rx7O_o4AI7",
        "outputId": "5b221462-1f4d-445a-e962-41816276db63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 41.723712 M\n"
          ]
        }
      ],
      "source": [
        "model = Transformer(vocab_size, vocab_size, n_embd, n_head, n_layer, dropout, max_seq_len).to(device)\n",
        "\n",
        "p = sum(p.nelement() for p in model.parameters())\n",
        "print(f\"Number of parameters: {p / 1e6} M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mibNyCC47nC"
      },
      "source": [
        "<h4>Model Training</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3ffFW9Gk4seP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# lr decay\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "epochs = 10\n",
        "model_save_path = '/content/drive/My Drive/transformer_En-De.pth'\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "try:\n",
        "  for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for i, (src, tgt) in enumerate(train_loader):\n",
        "      src = src.to(device)\n",
        "      tgt = tgt.to(device)\n",
        "\n",
        "      src_mask = make_src_mask(src, pad_idx).to(device)\n",
        "      tgt_input = tgt[:, :-1]\n",
        "      tgt_output = tgt[:, 1:]\n",
        "      tgt_mask = make_tgt_mask(tgt_input, pad_idx).to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(src, tgt_input, src_mask, tgt_mask)\n",
        "      loss = criterion(output.contiguous().view(-1, output.size(-1)), tgt_output.contiguous().view(-1))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      if i % 100 == 0:\n",
        "        print(f\"Batch {i} / {len(train_loader)}, training loss: {loss.item()}\")\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    print(f\"Epoch {epoch+1}, training loss: {avg_train_loss}\")\n",
        "\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f\"Model saved after epoch {epoch+1} to {model_save_path}\")\n",
        "\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for i, (src, tgt) in enumerate(val_loader):\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        src_mask = make_src_mask(src, pad_idx).to(device)\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_output = tgt[:, 1:]\n",
        "        tgt_mask = make_tgt_mask(tgt_input, pad_idx).to(device)\n",
        "\n",
        "        output = model(src, tgt_input, src_mask, tgt_mask)\n",
        "        loss = criterion(output.contiguous().view(-1, output.size(-1)), tgt_output.contiguous().view(-1))\n",
        "        total_val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    print(f\"Epoch {epoch+1}, validation loss: {avg_val_loss}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Epoch {epoch+1}, time: {end_time - start_time}\")\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Training interrupted. Saving model...\")\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f2625cb"
      },
      "source": [
        "#### Load and Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26a29c12",
        "outputId": "400e71dd-2d43-457e-f0d4-08b83752823d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "model_load_path = '/content/drive/My Drive/transformer_En-De.pth'\n",
        "\n",
        "loaded_model = Transformer(vocab_size, vocab_size, n_embd, n_head, n_layer, dropout, max_seq_len).to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_load_path, map_location=device))\n",
        "loaded_model.eval()\n",
        "\n",
        "print(\"Model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "95c57643"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(model, sentence, sp_en, sp_de, max_seq_len, device, pad_idx, start_symbol=1, end_symbol=2):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded_sentence = sp_en.encode(sentence, out_type=int)\n",
        "        src_tensor = torch.tensor(encoded_sentence, dtype=torch.long).unsqueeze(0).to(device)\n",
        "        src_mask = make_src_mask(src_tensor, pad_idx).to(device)\n",
        "\n",
        "        encoder_outputs = model.encode(src_tensor, src_mask)\n",
        "\n",
        "        tgt_tensor = torch.tensor([[start_symbol]], dtype=torch.long).to(device)\n",
        "\n",
        "        for _ in range(max_seq_len - 1):\n",
        "            tgt_mask = make_tgt_mask(tgt_tensor, pad_idx).to(device)\n",
        "\n",
        "            output = model.decode(encoder_outputs, src_mask, tgt_tensor, tgt_mask)\n",
        "            logits = model.generator(output[:, -1, :])\n",
        "\n",
        "            next_token = logits.argmax(dim=-1)\n",
        "\n",
        "            tgt_tensor = torch.cat([tgt_tensor, next_token.unsqueeze(0)], dim=1)\n",
        "\n",
        "            if next_token.item() == end_symbol:\n",
        "                break\n",
        "\n",
        "        output_tokens = tgt_tensor.squeeze(0).tolist()\n",
        "        if output_tokens[0] == start_symbol:\n",
        "            output_tokens = output_tokens[1:]\n",
        "        if end_symbol in output_tokens:\n",
        "            output_tokens = output_tokens[:output_tokens.index(end_symbol)]\n",
        "\n",
        "        translated_sentence = sp_de.decode(output_tokens)\n",
        "\n",
        "    return translated_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cc518e2"
      },
      "outputs": [],
      "source": [
        "# Test the translation\n",
        "test_sentence = \"my wife is very beautiful and i love her\"\n",
        "translated_output = translate_sentence(loaded_model, test_sentence, sp_en, sp_de, max_seq_len, device, pad_idx)\n",
        "print(f\"English: {test_sentence}\")\n",
        "print(f\"German: {translated_output}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
